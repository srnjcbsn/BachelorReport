#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass report
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 0
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Multi-Agent Systems
\end_layout

\begin_layout Subsection
Agents and Environments in Artificial Intelligence
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename MASNodeSearch.png
	lyxscale 30
	width 50text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
What an agent can see of a graph where it tries to move from node A to node
 B.
\begin_inset CommandInset label
LatexCommand label
name "fig:MASNodeSearch"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
In artificial intelligence, an agent is something that can perform actions
 in and (partially or fully) perceive the state of the environment it is
 situated in.
 As an example, consider an agent tasked with finding the shortest route
 between two nodes in a weighted, undirected graph, with the limitation
 that it can only see the nodes that have an edge to the one it is standing
 in, an example of the graph can be seen on fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:MASNodeSearch"

\end_inset

.
 We will now use this example to describe what (Russel, Norvig, 2010) calls
 a 
\emph on
task environment
\emph default
, consisting of definitions for the performance measure for the agent, the
 environment it acts in, the actions it can take, and its facilities for
 perception:
\end_layout

\begin_layout Description
Environment The environment is a model of the world the agent acts in.
 In our example, it is described as a graph.
 The environment may also contain artifacts for agents to interact with,
 such as a packages to pick up or obstacles to navigate around.
\end_layout

\begin_layout Description
Actions This denotes what actions the agent can take to change the state
 of the environment or itself.
 In the example, the agent would have a 
\emph on
move
\emph default
 action, allowing it to move to an adjacent, connected node.
\end_layout

\begin_layout Description
Percepts If the agent is to make intelligent decisions, it must be able
 to perceive the current state of the world -- that is, itself and the environme
nt.
 Such a fragment of information that the agent have sensed is called a percept.
 In the running example, the agent can perceive the nodes immediately connected
 to the one it is standing on, as well as the edges to those nodes.
\end_layout

\begin_layout Description
Performance For an agent to be as efficient as possible, it is useful to
 have a performance measure describing how well the agent is executing the
 task at hand.
 In the provided example, the performance measure could be defined in terms
 of the number of actions taken per unique node visited, giving the agent
 an idea of the amount of redundancy in its pathfinding.
\end_layout

\begin_layout Standard
While the task environment can be used to succinctly describe the properties
 of the world, it says nothing of the logic that the agent applies to perform
 tasks in the world.
 This is left in the hands of an 
\emph on
agent program
\emph default
, which is responsible for processing the percepts and choosing actions
 for an agent.
 In general, an agent program receives percepts and chooses an appropriate
 action based on the knowledge available to it in an aptly named 
\emph on
percept-action
\emph default
 
\emph on
cycle
\emph default
.
 This knowledge may just be the current percepts, or it may be all the percepts
 retreived so far.
 When choosing an action, it may take into consideration how different actions
 would affect the world, and how much closer performing the action would
 bring the agent to its goal.
 Agents with such capable agent programs are called 
\emph on
utility-based agents
\emph default
 in (Russel, Norvig, 2010).
\end_layout

\begin_layout Subsection
Multi-Agent Systems
\end_layout

\begin_layout Standard
While there is no strict, universal definition of what constitutes a multi-agent
 system, the following seems to represents the simplest consensus: 
\emph on
In a multi-agent system, several intelligent agents act and interact more
 or less autonomously in an environment
\emph default
.
 The interacting of agents may be of any character, the important part is
 that each agent can be aware of the others and affect their execution directly
 or indirectly.
 Here, a direct effect means changing another agents state, eg.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
 
\end_layout

\end_inset

by moving it into another postition or decreasing its health.
 An indirect effect could be communicating with the agent, suggesting another
 execution path.
 For instance, a system in which agents compete for ressources and hinder
 other agents' progress is a multi-agent system, as is a system in which
 the agents work together towards a common goal.
 
\end_layout

\begin_layout Standard
While the former may be useful in simulating certain systems, the latter
 is more interesting in software design, as such an approach could conceivably
 lead to more decentralized problem solving.
 A mixture of the two approaches can also be used, as in the Multi-Agent
 Programming Contest
\family typewriter
\emph on

\begin_inset Foot
status open

\begin_layout Plain Layout

\family typewriter
multiagentcontest.org
\end_layout

\end_inset


\family default
\emph default
, where teams of cooperating agents compete for points.
 In this case, the goal for each team is to develop the best strategy, where
 performance is measured by competitiveness.
\end_layout

\begin_layout Standard
In addition to the above, limiting the agents' knowledge of the state of
 the world is a desirable characteristic of a MAS; otherwise, there would
 be no need for the agents to communicate, and they could just as well be
 subroutines of a single agent (Panait and Luke, 2005).
 It could still be modelled as a MAS, of course, but not a very interisting
 one.
 Additionally, the case could be made that the less agents know of the world,
 the less information they have to process when searching for an action
 to execute, thus reducing their computational load.
 On the other hand, less information can cause the agent to follow a suboptimal
 execution path, causing a trade-off between computation time and optimality.
 
\end_layout

\begin_layout Standard
One of the strong points of multi-agent systems is that it consists of several
 pieces of software running more or less autonomously.
 As mentioned above, this allows for developing decentralized systems, where
 agent programs runs on different threads or servers.
 In the context of distributed systems, less dependency on a central intelligenc
e is of course preferred.
 
\end_layout

\begin_layout Standard
Furthermore, MASs are useful when simulating naturally occuring systems
 wherein several 
\begin_inset Quotes eld
\end_inset

agents
\begin_inset Quotes erd
\end_inset

 interact with each other An example of this could be a group of animals
 around a watering hole, where some are prey and some are predators.
\end_layout

\begin_layout Subsection
The GOAL Agent Programming Language
\end_layout

\begin_layout Standard
In this section we will outline the GOAL language based on 
\begin_inset ERT
status open

\begin_layout Plain Layout

~
\backslash
cite{Hindriks06}
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
Several APLs (Agent Programming Languages) have been developed to suit the
 defining characters of agents and their interaction with environments as
 we have described them above.
 In this section, we will focus on the relatively new GOAL APL, which can
 be written using the prolog logic programming language.
\end_layout

\begin_layout Standard
In GOAL, code is segmented into sections describing:
\end_layout

\begin_layout Itemize
What it knows
\end_layout

\begin_layout Itemize
What it wants to achieve
\end_layout

\begin_layout Itemize
What it can do
\end_layout

\begin_layout Itemize
How it handles new information (percepts) from the environment
\end_layout

\begin_layout Itemize
The actual logic for choosing an appropriate action to execute
\end_layout

\begin_layout Standard
The first two points in the list will be explained below.
 
\end_layout

\begin_layout Subsubsection*
Mental State
\end_layout

\begin_layout Standard
GOAL provides the notion of 
\emph on
mental state
\emph default
 of an agent, which describes what the agent knows and what it aims to achieve.
 Specifically, it consists of the following three components:
\end_layout

\begin_layout Description
Knowledge describes what the engine knows to be universally true.
 This information is completely static; it is something the agent is 
\begin_inset Quotes eld
\end_inset

born
\begin_inset Quotes erd
\end_inset

 with, and can not be changed.
 In other words, this describes the rules and constants of the system.
\end_layout

\begin_layout Description
Beliefs are facts the agent deduces during its execution, using its knowledge.
 Beliefs can be updated at runtime by using the 
\family typewriter
insert(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 and 
\family typewriter
delete(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 commands, where
\family typewriter
 
\begin_inset Formula $\varphi$
\end_inset


\family default
 is a belief.
 The 
\family typewriter
bel(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 operation can be used to ascertain whether the agent believes that 
\begin_inset Formula $\varphi$
\end_inset

 holds.
\end_layout

\begin_layout Description
Goals are what the agent strives to accomplish.
 These can be dynamically updated along the way to acommodate for a changing
 world.
 This is done with the 
\family typewriter
adopt(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 and 
\family typewriter
drop(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 commands, where 
\begin_inset Formula $\varphi$
\end_inset

 is a goal.
 
\family typewriter
goal(
\begin_inset Formula $\varphi$
\end_inset

)
\family default
 checks whether 
\begin_inset Formula $\varphi$
\end_inset

 is currently a goal of the agent.
 If a goal have been achieved -- that is, if the agent's current beliefs
 and knowledge satifies a goal -- it is automatically removed from the 
\family typewriter
goals
\family default
 collection, as the agent would otherwise keep trying to accomplish it.
 
\end_layout

\begin_layout Standard
The information in the mental state is stored as logical statements in prolog.
 The operations mentioned above for querying and modifying the mental state
 thus takes a prolog statement as input.
\end_layout

\begin_layout Subsubsection*
Acting and Perceiving
\end_layout

\begin_layout Standard
When a GOAL program is run, it executes the following steps, in order:
\end_layout

\begin_layout Enumerate
Receive percepts
\end_layout

\begin_layout Enumerate
Update the goals and beliefs of the agent if needed
\end_layout

\begin_layout Enumerate
Choose an appropriate action to execute
\end_layout

\begin_layout Standard
This is repeated in a cycle.
 
\end_layout

\begin_layout Standard
The processing of new percepts mentioned in point #2 is handled in the 
\family typewriter
event module
\family default
 of the agent program.
 Here, all new percepts in the current cycle can be inspected, and the mental
 state of the agent can be updated.
 If, for example, the agent perceives that it is in a different location
 than in the previous cycle, this module can be used to change its beliefs
 accordingly.
 If the world have changed drastically, the agent may also choose to drop
 goals that can no longer be achieved, and/or adopt goals that seems more
 fruitful to pursue.
 As such, the processing of percepts is the primary place to change the
 mental state of the agent.
\end_layout

\begin_layout Standard
The choosing of an action is where the agent decides -- based on its mental
 state -- which execution path it should take.
 The actions themselves are provided in an 
\family typewriter
action specification
\family default
 section of the program, where each action denotes pre- and postconditions
 of the action.
 That is, what must hold for the action to be executed and what effect it
 will have on the environment.
 An action is not considered for execution if its precondition does not
 hold.
 If it does hold and the action is taken, the logical statements in the
 postcondition is inserted into the belief base.
 
\end_layout

\begin_layout Standard
When an action have been chosen in GOAL, it is only 
\emph on
set
\emph default
 to be executed, that is, GOAL requests that it be executed.
 It might be that the program managing the agent in the environment sees
 fit to not execute it, or that the action fails (if the agent tries to
 move into a wall, for example).
 In that case, GOAL only knows about the failure of the action if it is
 somehow obvious from the next set of percepts it receives.
 In light of this, postconditions on actions should only be used when it
 absolutely certain that what the postcondition specifies is true, as it
 may otherwise insert flawed information into the agents beliefs.
\end_layout

\begin_layout Subsection
The Environment Interface Standard
\end_layout

\begin_layout Standard
Several agent programming languages -- including GOAL -- is only concerned
 with the agent logic of a MAS.
 To provide a world in which these agents can function, they need to be
 connected to a program providing an environment.
 
\end_layout

\begin_layout Standard
EIS (Environment Interface Standard) 
\family typewriter
\emph on
[Reference EIS technical report]
\family default
\emph default
 is a Java framework, which can be used to design environments and connect
 them to agent programming languages.
 As such, it does not assume much about the implementation of the environments
 or the agents inhabiting it.
 
\end_layout

\begin_layout Standard
It provides 
\family typewriter
entities
\family default
 which can function as the bodies of agent programs, and means for receiveing
 commands and returning percepts to the connected agents.When using EIS,
 the environment designer can handle actions sent by the agent programs
 with the 
\family typewriter
performAction
\family default
 method to define exactly how they affect the world the designer have constructe
d.
 Percepts can be requested explicitly through the 
\family typewriter
getAllPercepts
\family default
 method (this is how GOAL gets its percepts from EIS) or as notifications,
 for APLs that support it.
 
\end_layout

\begin_layout Standard
The main point of EIS is to provide a standard (hence the name) for developing
 MASs, such that environments designed with this standard can easily be
 interfaced with different APLs.
 As such, EIS comes pre-loaded with bindings for several common APLs such
 as GOAL and Jason.
 As part of this standard, the IILang (Interface Immediate Language) abstract
 syntax tree have been developed.
 It can be used to easily and unambiguously define actions and percepts
 consisting of identifiers, numerals, representations of functions over
 identifiers and numerals, and lists of identifiers, numerals and functions.
 These IILang objects can be created as native Java objects and easily parsed
 to -- in the case of GOAL -- prolog statements, and vice versa.
\end_layout

\begin_layout Standard
In conclusion, it is important to note that GOAL and EIS are supposed to
 be two components of a multi-agent system.
 GOAL is not supposed to maintain an environment, and EIS is not very well
 suited for implementing agent logic.
\end_layout

\begin_layout Subsubsection*
References
\end_layout

\begin_layout Standard
Stuart J.
 Russel, Peter Norvig, 
\begin_inset Quotes eld
\end_inset

Artificial Intelligence: A Modern Approach
\begin_inset Quotes erd
\end_inset

, Prentice Hall, Upper Saddle River, New Jersey 07458, 3rd ed., 2010
\begin_inset Newline newline
\end_inset


\end_layout

\begin_layout Standard
Panait, Luke, 
\begin_inset Quotes eld
\end_inset

Cooperative Multi-Agent Learning: The State of the Art
\begin_inset Quotes erd
\end_inset

, Autonomous Agents and Multi-Agent Systems, Volume 11, Issue 3, pp.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
 
\end_layout

\end_inset

387-434, 2005.
\end_layout

\end_body
\end_document
